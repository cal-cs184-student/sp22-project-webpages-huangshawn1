<html>
	<style>
	@media print {
	    .pagebreak { page-break-before: always; } /* page-break-after works, as well */
	}
	#images{
    	text-align:center;
    	margin:50px auto; 
	}
	#images a{
	    margin:0px 20px;
	    display:inline-block;
	    text-decoration:none;
	    color:black;
	}
	</style>
	<head>
	</head>
	<body>
		Part 1<br>
		To generate a ray we first map a point in image space to a point on the sensor in camera space using the horizontal and vertical field of view. This gives us the direction for the ray. We can then use the camera-to-world rotation matrix to get our final ray in world space. Then we need to figure out the radiance for each pixel in image space. We can do this by using our generated rays to figure out the radiance along the ray and using Monte Carlo sampling to estimate the overall radiance for each pixel.<br>
		To find the intersections a ray has with a triangle or sphere, we can simply apply the formulas from lecture slides, which factor in things such as the points of the triangle, center and radius of the sphere, and origin and direction of the ray. Doing this gives us points of intersection as well as the time of the intersection. We can use the point of intersection to render the image. We can use the time of intersection to only account for the closest intersection, so that objects properly block rays from hitting further objects.<br>
		The triangle intersection algorithm I used was the Moller Trumbore Algorithm from Lecture 9. This algorithm factors in the points of the triangle and the origin and direction of the ray to give us t (time of intersection) and b1 and b2 (barycentric coordinates for the intersection point).<br><br>
		<img src='part_1_1.png' width='350'><img src='part_1_2.png' width='350'><br>
		<img src='part_1_3.png' width='350'><img src='part_1_4.png' width='350'><br><br>

		<div class="pagebreak"> </div>

		Part 2<br>
		To construct the BVH we first loop through all primitives, expanding the bounding box to include all of them and figuring out the minimum and maximum x, y, and z values. If we have few enough primitives we can just return a leaf node. Otherwise, we find the longest axis based on the minimum and maximum values and split this axis in half geometrically. We then partition all our primitives into a left and right portion based on this midpoint and recursively construct the left and right nodes accordingly.<br>
		I rendered the dragon in 1.0605s, Lucy in 0.8509s, the bunny in 0.9220s, and the blob in 2.0438s (64 samples, 480x360, 8 threads).<br><br>
		<img src='part_2_1.png' width='350'><img src='part_2_2.png' width='350'><br>
		<img src='part_2_3.png' width='350'><img src='part_2_4.png' width='350'><br><br>
		I rendered a few images with 8 threads at 800x600. The cow took 6.8793s without BVH and 0.0477s with. The beetle took 9.4634s without and 0.0305s with. The beast took 117.1420s without and 0.0373s with. The bunny took 65.5403s without and 0.0367s with. As we can see BVH makes a huge difference for these renderings. While the more complex renderings quickly scaled up to take 1-2 minutes without BVH, the time it took with BVH stayed relatively similar at only 0.03-0.04 seconds.

	</body>
</html>